#!/bin/bash
set -e  # faz o script parar se algum comando der erro

echo "=============================="
echo "üöÄ Iniciando Babix IA com Ollama local..."
echo "=============================="

# Inicia o Ollama em segundo plano
ollama serve &
OLLAMA_PID=$!

# Aguarda o Ollama inicializar
echo "‚è≥ Aguardando Ollama iniciar..."
sleep 15

# Testa o modelo Phi-3
if ! ollama list | grep -q "phi3"; then
  echo "üì¶ Baixando modelo Phi-3..."
  ollama pull phi3 || echo "‚ö†Ô∏è Falha ao baixar modelo Phi-3, continuando..."
else
  echo "‚úÖ Modelo Phi-3 j√° dispon√≠vel!"
fi

# Executa a inicializa√ß√£o do aprendizado
echo "üß† Preparando banco e aprendizado inicial..."
python3 iniciar_babix.py || echo "‚ö†Ô∏è Erro ao inicializar Babix, continuando..."

# Inicia o servidor FastAPI
echo "‚úÖ Iniciando servidor FastAPI..."
uvicorn backend.main:app --host 0.0.0.0 --port ${PORT:-8080} &

# Mant√©m o Ollama ativo e impede que o container encerre
wait $OLLAMA_PID
