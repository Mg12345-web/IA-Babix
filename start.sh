#!/bin/bash
echo "=============================="
echo "üöÄ Iniciando Babix IA com Ollama local..."
echo "=============================="

# Inicia o Ollama em segundo plano
ollama serve &
OLLAMA_PID=$!

# Aguarda o Ollama inicializar
echo "‚è≥ Aguardando Ollama iniciar..."
sleep 15

# Testa o modelo
if ! ollama list | grep -q "phi3"; then
  echo "üì¶ Baixando modelo Phi-3..."
  ollama pull phi3
fi

# Executa inicializa√ß√£o do aprendizado
echo "üß† Preparando banco e aprendizado inicial..."
python3 iniciar_babix.py || echo "‚ö†Ô∏è Erro ao inicializar Babix, continuando..."

# Inicia o servidor FastAPI
echo "‚úÖ Iniciando servidor FastAPI..."
uvicorn backend.main:app --host 0.0.0.0 --port ${PORT:-8080}

# Mant√©m o container ativo
wait $OLLAMA_PID
