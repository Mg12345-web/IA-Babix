# ======================================================
# ðŸ§  Babix IA â€” IA AutÃ´noma com Ollama (instalaÃ§Ã£o direta)
# ======================================================

FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

# -------------------------
# ðŸ”¹ Instala dependÃªncias
# -------------------------
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    python3 \
    python3-pip \
    sqlite3 \
    git \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# -------------------------
# ðŸ”¹ Instala Ollama manualmente (sem install.sh)
# -------------------------
RUN wget https://github.com/ollama/ollama/releases/download/v0.1.47/ollama-linux-amd64.tgz && \
    tar -xvzf ollama-linux-amd64.tgz && \
    mv ollama /usr/local/bin/ && \
    rm ollama-linux-amd64.tgz

# -------------------------
# ðŸ”¹ Define diretÃ³rio de trabalho
# -------------------------
WORKDIR /app

# Copia tudo para o container
COPY . .

# -------------------------
# ðŸ”¹ Instala dependÃªncias Python
# -------------------------
RUN pip install --no-cache-dir -r requirements.txt

# -------------------------
# ðŸ”¹ Baixa modelo local
# -------------------------
RUN ollama pull phi3 || true

# -------------------------
# ðŸ”¹ Define variÃ¡veis e porta
# -------------------------
ENV PORT=8080
EXPOSE 8080

# -------------------------
# ðŸ”¹ Comando de inicializaÃ§Ã£o
# -------------------------
CMD ["bash", "start.sh"]
